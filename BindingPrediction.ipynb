{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy3teqLuUO0a"
   },
   "source": [
    "# Binding Prediction via API\n",
    "\n",
    "http://tools.iedb.org/main/tools-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Read in Conserved Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_csv_filenames(dirname):\n",
    "    '''\n",
    "    Returns a list of fully-qualified filenames \n",
    "    in dirname which end with \".csv\".\n",
    "    '''\n",
    "    csv_files = []\n",
    "    for f in os.listdir(dirname):\n",
    "        if f.endswith('.csv'):\n",
    "            csv_files.append(dirname + '/'+ f)\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def build_conserved_dataframe(filelist):\n",
    "    '''\n",
    "    Reads in all data from the files in the given filelist and\n",
    "    returns one DataFrame in which all data is appended together.\n",
    "    '''\n",
    "    dlist = []\n",
    "    for f in filelist:\n",
    "        \n",
    "        # read in dataframe for each file\n",
    "        df = pd.read_csv(f)\n",
    "        \n",
    "        # validation for dimensions\n",
    "        if df.shape[1] != 4:\n",
    "            raise ValueError('File does not contain the required number of columns:', f)\n",
    "        \n",
    "        # add dataframe to list\n",
    "        dlist.append(df)\n",
    "        \n",
    "    return pd.concat(dlist, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test get_csv_filenames()\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/ConservedRegion_Ryan/MERS_Conserved copy 2.csv',\n",
       " 'data/ConservedRegion_Ryan/MERS_Conserved.csv',\n",
       " 'data/ConservedRegion_Ryan/MERS_Conserved copy.csv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test get_csv_filenames()')\n",
    "\n",
    "print(get_csv_filenames('data'))\n",
    "\n",
    "get_csv_filenames('data/ConservedRegion_Ryan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test build_conserved_dataframe()')\n",
    "\n",
    "build_conserved_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Define Alleles-Length combinations to test\n",
    "The API allows us to define multiple alleles to predicting binding against, as well as multiple lengths for each of those alleles. \n",
    "\n",
    "The parameters must be listed as \n",
    "```allele='Allele1,Allele2'```\n",
    "and\n",
    "```length='Length1,Length2'```\n",
    "where each length matches the order of alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_alleles_and_length_strings(alleles,lengths):\n",
    "    '''\n",
    "    Given a list of alleles and list of lengths, generates two\n",
    "    strings: (1) an allele string; (2) a lengths string, then\n",
    "    returns a tuple (alleles_string, lengths_string).\n",
    "    \n",
    "    For each length in lengths, every allele in alleles is\n",
    "    concatenated into a single comma-delimited string. For\n",
    "    each allele in alleles, every length in lengths is \n",
    "    concatenated into a single comma-delimited string.    \n",
    "    \n",
    "    For example, given lengths=[1,2] and alleles=['A','B']:\n",
    "    \n",
    "    alleles_string='A,B,A,B'\n",
    "    lengths_string='1,1,2,2'\n",
    "    '''\n",
    "    \n",
    "    a_list = list()\n",
    "    l_list = list()\n",
    "    \n",
    "    for l in lengths:\n",
    "        a_list += alleles # create a copy of the alleles for each length\n",
    "        l_list += [str(l) for i in range(len(alleles))] # generate a length for each allele in the copy\n",
    "        \n",
    "    # concatenate elements in each list with comma separator\n",
    "    joined_a = \",\".join(a_list)\n",
    "    joined_l = \",\".join(l_list)\n",
    "    \n",
    "    return (joined_a,joined_l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test build_alleles_and_length_strings()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('HLA-A*01:01,HLA-A*02:01,HLA-A*01:01,HLA-A*02:01', '9,9,10,10')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test build_alleles_and_length_strings()')\n",
    "\n",
    "hla_ref_set_test = ['HLA-A*01:01','HLA-A*02:01']\n",
    "lengths_list_test = [9,10]\n",
    "build_alleles_and_length_strings(hla_ref_set_test,lengths_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "    \n",
    "def predict_mhc1(a_set,l_set,sequence):\n",
    "    '''\n",
    "    Note that the default value for species is human.\n",
    "    '''\n",
    "    \n",
    "    # define post\n",
    "    data = {'method':'recommended',\n",
    "            'allele':a_set,\n",
    "            'length':l_set,\n",
    "            'sequence_text':sequence}\n",
    "\n",
    "    site = 'http://tools-cluster-interface.iedb.org/tools_api/mhci/'  \n",
    "\n",
    "    # perform prediction\n",
    "    return requests.post(site, data=data)\n",
    "\n",
    "import csv\n",
    "\n",
    "def save_result(response, filename):\n",
    "    \n",
    "    with open(filename, mode='w') as write_file:\n",
    "        file_writer = csv.writer(write_file, delimiter=',')\n",
    "\n",
    "        for each_row in response.text.split('\\n'):\n",
    "            file_writer.writerow(each_row.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Data in the following file does not contain the required number of columns:', 'data/ConservedRegion_Ryan/MERS_Conserved copy 2.csv')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-52197a2b277a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_csv_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ConservedRegion_Ryan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbuild_conserved_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-c3c48bb69af1>\u001b[0m in \u001b[0;36mbuild_conserved_dataframe\u001b[0;34m(filelist)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# validation for dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data in the following file does not contain the required number of columns:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# add dataframe to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Data in the following file does not contain the required number of columns:', 'data/ConservedRegion_Ryan/MERS_Conserved copy 2.csv')"
     ]
    }
   ],
   "source": [
    "files = get_csv_filenames('data/ConservedRegion_Ryan')\n",
    "\n",
    "build_conserved_dataframe(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHC I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLA allele reference set (27 alleles long)\n",
    "hla_ref_set_mhc1 = ['HLA-A*01:01','HLA-A*02:01','HLA-A*02:03','HLA-A*02:06','HLA-A*03:01','HLA-A*11:01','HLA-A*23:01','HLA-A*24:02','HLA-A*26:01','HLA-A*30:01','HLA-A*30:02','HLA-A*31:01','HLA-A*32:01','HLA-A*33:01','HLA-A*68:01','HLA-A*68:02','HLA-B*07:02','HLA-B*08:01','HLA-B*15:01','HLA-B*35:01','HLA-B*40:01','HLA-B*44:02','HLA-B*44:03','HLA-B*51:01','HLA-B*53:01','HLA-B*57:01','HLA-B*58:01']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for this prediction\n",
    "read_file = 'data/Binding_Prediction/mhc1_test1/mhc1_test1_api_seq.txt'\n",
    "write_file = 'data/Binding_Prediction/mhc1_test1/mhc1_test1_api_result.csv'\n",
    "allele_list = hla_ref_set_mhc1\n",
    "lengths_list = [9,10]\n",
    "\n",
    "# perform prediction for this sequence\n",
    "seq = read_data(read_file)\n",
    "a_str,l_str = build_alleles_and_length_strings(allele_list, lengths_list)\n",
    "r1 = predict_mhc1(a_str,l_str,seq)\n",
    "save_result(r1, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine results into single csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHC II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLA allele reference set\n",
    "hla_ref_set_mhc2 = ['HLA-DRB1*01:01','HLA-DRB1*03:01','HLA-DRB1*04:01','HLA-DRB1*04:05','HLA-DRB1*07:01','HLA-DRB1*08:02','HLA-DRB1*09:01','HLA-DRB1*11:01','HLA-DRB1*12:01','HLA-DRB1*13:02','HLA-DRB1*15:01','HLA-DRB3*01:01','HLA-DRB3*02:02','HLA-DRB4*01:01','HLA-DRB5*01:01','HLA-DQA1*05:01/DQB1*02:01','HLA-DQA1*05:01/DQB1*03:01','HLA-DQA1*03:01/DQB1*03:02','HLA-DQA1*04:01/DQB1*04:02','HLA-DQA1*01:01/DQB1*05:01','HLA-DQA1*01:02/DQB1*06:02','HLA-DPA1*02:01/DPB1*01:01','HLA-DPA1*01:03/DPB1*02:01','HLA-DPA1*01:03/DPB1*04:01','HLA-DPA1*03:01/DPB1*04:02','HLA-DPA1*02:01/DPB1*05:01','HLA-DPA1*02:01/DPB1*14:01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mhc2(a_set,l_set,sequence):\n",
    "    '''\n",
    "    API doesn't appear to allow us to set species/locus.\n",
    "    '''\n",
    "    \n",
    "    # define post\n",
    "    data = {'method':'recommended',\n",
    "            'allele':a_set,\n",
    "            'length':l_set,\n",
    "            'sequence_text':sequence}\n",
    "\n",
    "    site = 'http://tools-cluster-interface.iedb.org/tools_api/mhcii/'  \n",
    "\n",
    "    # perform prediction\n",
    "    return requests.post(site, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for this prediction\n",
    "read_file = 'data/Binding_Prediction/mhc2_test2/mhc2_test2_api_seq.txt'\n",
    "write_file = 'data/Binding_Prediction/mhc2_test2/mhc2_test2_api_result.csv'\n",
    "allele_list = hla_ref_set_mhc2\n",
    "lengths_list = [15,16]\n",
    "\n",
    "# perform prediction for this sequence\n",
    "seq = read_data(read_file)\n",
    "a_str,l_str = build_alleles_and_length_strings(allele_list, lengths_list)\n",
    "r2 = predict_mhc2(a_str,l_str,seq)\n",
    "save_result(r2, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02-518/02-718 Homework 4 Template",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
